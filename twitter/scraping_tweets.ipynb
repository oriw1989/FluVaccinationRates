{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made changes to the GetOldTweets python3 library and added ability\n",
    "# to search within location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetOldTweets_python import got3\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import time, csv, os\n",
    "from collections import Counter\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import api_keys\n",
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the city, state dataframe to get a list of cities + states of interest\n",
    "\n",
    "states = {\n",
    "    'Alabama': 'Montgomery',\n",
    "    'Alaska': 'Juneau',\n",
    "    'Arizona':'Phoenix',\n",
    "    'Arkansas':'Little Rock',\n",
    "    'California': 'Sacramento',\n",
    "    'Colorado':'Denver',\n",
    "    'Connecticut':'Hartford',\n",
    "    'Delaware':'Dover',\n",
    "    'Florida': 'Tallahassee',\n",
    "    'Georgia': 'Atlanta',\n",
    "    'Hawaii': 'Honolulu',\n",
    "    'Idaho': 'Boise',\n",
    "    'Illinois': 'Springfield',\n",
    "    'Indiana': 'Indianapolis',\n",
    "    'Iowa': 'Des Monies',\n",
    "    'Kansas': 'Topeka',\n",
    "    'Kentucky': 'Frankfort',\n",
    "    'Louisiana': 'Baton Rouge',\n",
    "    'Maine': 'Augusta',\n",
    "    'Maryland': 'Annapolis',\n",
    "    'Massachusetts': 'Boston',\n",
    "    'Michigan': 'Lansing',\n",
    "    'Minnesota': 'St. Paul',\n",
    "    'Mississippi': 'Jackson',\n",
    "    'Missouri': 'Jefferson City',\n",
    "    'Montana': 'Helena',\n",
    "    'Nebraska': 'Lincoln',\n",
    "    'Nevada': 'Carson City',\n",
    "    'New Hampshire': 'Concord',\n",
    "    'New Jersey': 'Trenton',\n",
    "    'New Mexico': 'Santa Fe',\n",
    "    'New York': 'Albany',\n",
    "    'North Carolina': 'Raleigh',\n",
    "    'North Dakota': 'Bismarck',\n",
    "    'Ohio': 'Columbus',\n",
    "    'Oklahoma': 'Oklahoma City',\n",
    "    'Oregon': 'Salem',\n",
    "    'Pennsylvania': 'Harrisburg',\n",
    "    'Rhode Island': 'Providence',\n",
    "    'South Carolina': 'Columbia',\n",
    "    'South Dakota': 'Pierre',\n",
    "    'Tennessee': 'Nashville',\n",
    "    'Texas': 'Austin',\n",
    "    'Utah': 'Salt Lake City',\n",
    "    'Vermont': 'Montpelier',\n",
    "    'Virginia': 'Richmond',\n",
    "    'Washington': 'Olympia',\n",
    "    'West Virginia': 'Charleston',\n",
    "    'Wisconsin': 'Madison',\n",
    "    'Wyoming': 'Cheyenne'  \n",
    "}\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "us_state_size = {\n",
    "    'Alabama': 50750,\n",
    "    'Alaska': 570641,\n",
    "    'Arizona': 113642,\n",
    "    'Arkansas': 52075,\n",
    "    'California': 155973,\n",
    "    'Colorado': 103730,\n",
    "    'Connecticut': 4845,\n",
    "    'Delaware': 1955,\n",
    "    'Florida': 53997,\n",
    "    'Georgia': 57919,\n",
    "    'Hawaii': 6423,\n",
    "    'Idaho': 82751,\n",
    "    'Illinois': 55593,\n",
    "    'Indiana': 35870,\n",
    "    'Iowa': 55875,\n",
    "    'Kansas': 81823,\n",
    "    'Kentucky': 39732,\n",
    "    'Louisiana': 43566,\n",
    "    'Maine': 30865,\n",
    "    'Maryland': 9775,\n",
    "    'Massachusetts': 7838,\n",
    "    'Michigan': 56539,\n",
    "    'Minnesota': 79617,\n",
    "    'Mississippi': 46914,\n",
    "    'Missouri': 68898,\n",
    "    'Montana': 145556,\n",
    "    'Nebraska': 76878,\n",
    "    'Nevada': 109806,\n",
    "    'New Hampshire': 8969,\n",
    "    'New Jersey': 7419,\n",
    "    'New Mexico': 121365,\n",
    "    'New York': 47224,\n",
    "    'North Carolina': 48718,\n",
    "    'North Dakota': 68994,\n",
    "    'Ohio': 40953,\n",
    "    'Oklahoma': 68679,\n",
    "    'Oregon': 96003,\n",
    "    'Pennsylvania': 44820,\n",
    "    'Rhode Island': 1034,\n",
    "    'South Carolina': 30111,\n",
    "    'South Dakota': 75898,\n",
    "    'Tennessee': 41220,\n",
    "    'Texas': 261914,\n",
    "    'Utah': 82168,\n",
    "    'Vermont': 9249,\n",
    "    'Virginia': 39598,\n",
    "    'Washington': 66582,\n",
    "    'West Virginia': 24087,\n",
    "    'Wisconsin': 54314,\n",
    "    'Wyoming': 97105,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape tweets and write them to a csv file\n",
    "def get_tweets(start_date, end_date, interval, search_term, location, within, \n",
    "               nTweets, ftag=\"\"):\n",
    "    # Generate csv file name\n",
    "    if len(ftag) > 0:\n",
    "        ftag = \"_\" + ftag\n",
    "\n",
    "    fname = start_date + \"_\" + end_date + ftag + \"_tweets.csv\"\n",
    "    fname = os.path.join(data_dir, fname)\n",
    "    \n",
    "    # Generate lists of start and end dates\n",
    "    date_range = [d.strftime('%Y-%m-%d') for d in \n",
    "                  pd.date_range(start=start_date, end=end_date, freq=interval)]\n",
    "    date_range.insert(0, start_date)\n",
    "    start_date_range = date_range[:-1]\n",
    "    end_date_range = date_range[1:]\n",
    "\n",
    "    print('Scraping data from {}'.format(location))\n",
    "\n",
    "    for i, (start_date, end_date) in enumerate(zip(start_date_range, end_date_range)):\n",
    "        print('Processing {}/{} periods'.format(i+1, len(start_date_range)))\n",
    "        \n",
    "        time.sleep(10)\n",
    "        # Create tweetCriteria object\n",
    "        tweetCriteria = got3.manager.TweetCriteria()\n",
    "        # if location is specified\n",
    "        if location:\n",
    "            tweetCriteria.setNear(location).setWithin(within)\n",
    "    \n",
    "        tweetCriteria.setQuerySearch(search_term).setMaxTweets(nTweets)\n",
    "        tweetCriteria.setSince(start_date).setUntil(end_date)\n",
    "        results = got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "        # print number of results returned\n",
    "        print('{} tweets found'.format(len(results)))\n",
    "        with open(fname, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for result in results:\n",
    "                date = result.date.strftime('%Y-%m-%d')\n",
    "                values = [result.id, result.permalink, result.username, \n",
    "                          result.text, date, result.retweets, \n",
    "                          result.favorites, result.mentions, result.hashtags, \n",
    "                          result.geo, location, search_term]\n",
    "                \n",
    "                csv_writer(writer, values, os.path.isfile(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write rows to csv\n",
    "def csv_writer(writer, values, file_exist):\n",
    "    if not file_exist:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search terms to scrape tweets\n",
    "search_terms = ['#flushot', 'flu shot', 'flu shots', 'flu', 'flu vaccine', 'flu vaccines', \n",
    "                'influenza', 'flu vaccinations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to time concern, only scraping 3 terms for now\n",
    "search_term = search_terms[0]\n",
    "print('query for {}'.format(search_term))\n",
    "for i, (state, city) in enumerate(states.items()):\n",
    "    location = '\"' + city + ', ' + us_state_abbrev[state] + '\"'\n",
    "    radius = str(int(us_state_size[state] ** (0.5))) + 'mi'\n",
    "    get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "            location, radius, 500)\n",
    "\n",
    "search_term = search_terms[3]\n",
    "print('query for {}'.format(search_term))\n",
    "for i, (state, city) in enumerate(states.items()):\n",
    "    location = '\"' + city + ', ' + us_state_abbrev[state] + '\"'\n",
    "    radius = str(int(us_state_size[state] ** (0.5))) + 'mi'\n",
    "    get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "            location, radius, 500)\n",
    "\n",
    "search_term = search_terms[4]\n",
    "print('query for {}'.format(search_term))\n",
    "for i, (state, city) in enumerate(states.items()):\n",
    "    location = '\"' + city + ', ' + us_state_abbrev[state] + '\"'\n",
    "    radius = str(int(us_state_size[state] ** (0.5))) + 'mi'\n",
    "    get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "            location, radius, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since most tweets do not have geotag, scrape tweets without location as well\n",
    "search_term = '#gotmyflushot'\n",
    "print('query for {}'.format(search_term))\n",
    "get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "           location=None, within=None, nTweets=3000, ftag='noLocation')\n",
    "\n",
    "search_term = 'got my flu shot'\n",
    "print('query for {}'.format(search_term))\n",
    "get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "           location=None, within=None, nTweets=3000, ftag='noLocation')\n",
    "\n",
    "search_term = 'flu symptom'\n",
    "print('query for {}'.format(search_term))\n",
    "get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "           location=None, within=None, nTweets=3000, ftag='noLocation')\n",
    "\n",
    "search_term = 'flu sick'\n",
    "print('query for {}'.format(search_term))\n",
    "get_tweets('2015-1-1', '2018-11-1', 'M', search_term, \n",
    "           location=None, within=None, nTweets=3000, ftag='noLocation')\n",
    "\n",
    "search_term = 'get your flu shot'\n",
    "print('query for {}'.format(search_term))\n",
    "get_tweets('2015-1-1', '2018-11-1', 'Y', search_term, \n",
    "           location=None, within=None, nTweets=30000, ftag='noLocation')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipythonP",
  "version": "Python 3.7.1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
