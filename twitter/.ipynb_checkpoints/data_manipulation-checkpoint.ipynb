{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re, string\n",
    "#from collections import Counter\n",
    "#import spacy\n",
    "import numpy as np\n",
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cdc_average_bystate.csv',\n",
       " '2015-1-1_2018-11-1_noLocation_tweets.csv',\n",
       " '2015-1-1_2018-11-1_noLocation_tweets_processed.csv',\n",
       " '.DS_Store',\n",
       " '2015-1-1_2018-11-1_flu_converage.csv',\n",
       " 'tweets_without_location.csv',\n",
       " 'us_cities_states_counties.csv',\n",
       " 'tweets_with_location.csv',\n",
       " '2015-1-1_2018-11-1_tweets.csv']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "data_dir = 'data'\n",
    "fieldnames=['id', 'permalink', 'username', 'text', 'date', \n",
    "            'retweets', 'favorites', 'mentions', 'hashtags', 'geo',\n",
    "            'location', 'search_term']\n",
    "\n",
    "#os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the tweeter dataframe\n",
    "converage_df = pd.read_csv(os.path.join(data_dir,'2015-1-1_2018-11-1_flu_converage.csv'))\n",
    "#cdc_df = pd.read_csv(os.path.join(data_dir, 'cdc_average_bystate.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider one search term for now\n",
    "converage_df['date'] = pd.to_datetime(converage_df['date'])\n",
    "converage_df = converage_df[converage_df['search_term'] == 'flu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of tweets by location, search_term, and time\n",
    "converage_df.set_index('date', inplace = True)\n",
    "transformed_df = converage_df.groupby(['search_term', 'location', pd.Grouper(freq='M')]).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the location to more useful format\n",
    "transformed_df = transformed_df.rename({0: 'count'}, axis=1)\n",
    "transformed_df['location'] = transformed_df['location'].map(lambda s: eval(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll the time up by 15 days to sync up with the google trend and cdc data\n",
    "transformed_df['date'] = transformed_df['date'].apply(lambda dt: dt.replace(day=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean up the search term \n",
    "#search_term_recode = dict(zip(transformed_df['search_term'].unique(), ['flushot', 'flushot', 'flu', 'flu_vaccine']))\n",
    "transformed_df['search_term'] = transformed_df['search_term'].map(search_term_recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "abbrev2state = {i: k for k, i in us_state_abbrev.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert state abbreviations to full name for consistency\n",
    "transformed_df['state'] = transformed_df['location'].apply(lambda s: abbrev2state[s.split(\", \")[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pivot table for easier merge down stream\n",
    "pivot_tb = transformed_df.pivot_table(index='date', columns=['search_term', 'state'])\n",
    "\n",
    "colnames = [col[2] for col in pivot_tb.columns]\n",
    "pivot_tb.columns = colnames\n",
    "\n",
    "pivot_tb = pivot_tb.fillna(0)\n",
    "\n",
    "# Save the data\n",
    "pivot_tb.to_csv(os.path.join(data_dir, 'tweets_with_location.csv'))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipythonP",
  "version": "Python 3.7.1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
